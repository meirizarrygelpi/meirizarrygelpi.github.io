<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>M.E. Irizarry-Gelpí</title><link href="http://meirizarrygelpi.github.io/" rel="alternate"></link><link href="http://meirizarrygelpi.github.io/feeds/maths.atom.xml" rel="self"></link><id>http://meirizarrygelpi.github.io/</id><updated>2015-05-06T00:00:00-04:00</updated><entry><title>The Triangle Product for 3-Hypermatrices</title><link href="http://meirizarrygelpi.github.io/posts/2015/May/triangle-product-3-hypermatrices/" rel="alternate"></link><updated>2015-05-06T00:00:00-04:00</updated><author><name>M.E. Irizarry-Gelpí</name></author><id>tag:meirizarrygelpi.github.io,2015-05-06:posts/2015/May/triangle-product-3-hypermatrices/</id><summary type="html">&lt;p&gt;Lately, I have been thinking about vectors, matrices and linear algebra. Indeed, I have been thinking about higher-dimensional generalizations of matrices, i.e. from two-dimensional arrays of numbers to three-dimensional arrays of numbers. This was triggered by reading &lt;a href="http://radar.oreilly.com/2015/03/lets-build-open-source-tensor-libraries-for-data-science.html"&gt;this blog post on tensors&lt;/a&gt;. In this post I will propose some generalizations to many of the properties of matrices to the case of 3-hypermatrices.&lt;/p&gt;
&lt;h2&gt;$k$-Orthotopic Arrays&lt;/h2&gt;
&lt;p&gt;A matrix is a rectangular array of elements. The 3-dimensional analog of a rectangle is the cuboid (also known as a 3-orthotope). Arranging elements into a cuboidal array yields what I will call a cuboidal 3-hypermatrix. A square matrix is a special case where the 2-dimensional array has a square shape. The 3-dimensional analog of a square is the cube. Arranging elements into a cubic array yields what I will call a cubic 3-hypermatrix.&lt;/p&gt;
&lt;p&gt;More generally, the $k$-dimensional analog of a rectangle is the $k$-orthotope, and the $k$-dimensional analog of a square is the $k$-cube. Arranging elements into a $k$-orthotopic array yields an orthotopic $k$-hypermatrix. Similarly, arranging elements into a $k$-cubic array yields a hypercubic $k$-hypermatrix.&lt;/p&gt;
&lt;p&gt;The discussion below will have the following form: I will first introduce a property of a matrix, then I will propose the analog of the property for 3-hypermatrices, and finally I will comment on the general case for $k$-hypermatrices.&lt;/p&gt;
&lt;h2&gt;Size&lt;/h2&gt;
&lt;p&gt;The size of a rectangular matrix $\mathbf{A}$ is given by a 2-tuple of natural numbers:
$$\operatorname{size}{(\mathbf{A})} = (m, n) \in \mathbb{N}^{2}.$$
Here $m$ is the number of rows, and $n$ is the number of columns. I will refer to $m$ as the capacity of the row-axis, and $n$ as the capacity of the column-axis. The set of all possible matrices with size $(m, n)$ is denoted by $\mathbb{A}_{m \times n}$. The set of all possible rectangular matrices is denoted by $\mathbb{A}_{2}$. It is given by
$$\mathbb{A}_{2} = \bigcup_{(m, n) \in \mathbb{N}^{2}} \mathbb{A}_{m \times n}.$$
The set of square matrices is a subset of this space. The 2-tuples of natural numbers can be arranged in a semi-infinite triangular array, similar to Pascal's triangle:
$$(1, 1)$$
$$(1, 2) \quad (2, 1)$$
$$(1, 3) \quad (2, 2) \quad (3, 1)$$
$$(1, 4) \quad (2, 3) \quad (3, 2) \quad (4, 1)$$
$$(1, 5) \quad (2, 4) \quad (3, 3) \quad (4, 2) \quad (5, 1)$$
The 2-tuple on top of the triangle describes the size of matrices that correspond to scalars (plain numbers). The left outer edge of the triangle describes the size of matrices that correspond to row vectors. Similarly, the right outer edge of the triangle describes the size of matrices that correspond to column vectors. Finally, the internal triangle, with $(2, 2)$ being on top, describes the size of rectangular matrices.&lt;/p&gt;
&lt;p&gt;In a similar manner, the size of an orthotopic 3-hypermatrix $\mathbf{A}$ is given by a 3-tuple of natural numbers:
$$\operatorname{size}{(\mathbf{A})} = (a, b, c) \in \mathbb{N}^{3}.$$
I will refer to $a$ as the capacity of the 1-axis, to $b$ as the capacity of the 2-axis, and $c$ as the capacity of the 3-axis. The set of all possible orthotopic 3-hypermatrices with size $(a, b, c)$ is denoted by $\mathbb{A}_{a \times b \times c}$. The set of all possible orthotopic 3-matrices is denoted by $\mathbb{A}_{3}$. It is given by
$$\mathbb{A}_{3} = \bigcup_{(a, b, c) \in \mathbb{N}^{3}} \mathbb{A}_{a \times b \times c}.$$
The set of cubic 3-hypermatrices is a subset of this space. The 3-tuples of natural numbers can be arranged in a semi-infinite tetrahedral array, similar to Pascal's tetrahedron. The top vertex of this tetrahedron describes the size of 3-hypermatrices that correspond to scalars. Each of the three edges from the top vertex correspond to the size of 3-hypermatrices that correspond to vectors (three kinds now). Each of the three faces correspond to the size of 3-hypermatrices that correspond to matrices. The internal tetrahedron, with the 3-tuple $(2, 2, 2)$ being on top, describes the size of orthotopic 3-hypermatrices.&lt;/p&gt;
&lt;p&gt;More generally, the size of an orthotopic $k$-hypermatrix $\mathbf{A}$ is given by a $k$-tuple of natural numbers:
$$\operatorname{size}{(\mathbf{A})} = t = (n_{1}, n_{2}, \ldots, n_{k}) \in \mathbb{N}^{k}.$$
I will refer to $n_{j}$ as the capacity of the $j$-axis. The set of all possible orthotopic $k$-hypermatrices with size $t$ is denoted by $\mathbb{A}_{t}$. The set of all possible orthotopic $k$-matrices is denoted by $\mathbb{A}_{k}$. It is given by
$$\mathbb{A}_{k} = \bigcup_{t \in \mathbb{N}^{k}} \mathbb{A}_{t}.$$
The set of hypercubic $k$-hypermatrices is a subset of this space.&lt;/p&gt;
&lt;h2&gt;Addition&lt;/h2&gt;
&lt;p&gt;Given two rectangular matrices $\mathbf{A}$ and $\mathbf{B}$, both with size $(m, n)$, the operation $\operatorname{add}_{2}(\mathbf{A}, \mathbf{B})$ returns a third matrix with size $(m, n)$. Thus,
$$\operatorname{add}_{2} : \mathbb{A}_{m \times n} \times \mathbb{A}_{m \times n} \longrightarrow \mathbb{A}_{m \times n}.$$
The elements of the matrix $\operatorname{add}_{2}(\mathbf{A}, \mathbf{B})$ are found by element-wise adding the elements of $\mathbf{A}$ with the elements of $\mathbf{B}$. The addition operation on matrices is commutative:
$$\operatorname{add}_{2}(\mathbf{A}, \mathbf{B}) = \operatorname{add}_{2}(\mathbf{B}, \mathbf{A}).$$
It is also associative:
$$\operatorname{add}_{2}(\operatorname{add}_{2}(\mathbf{A}, \mathbf{B}), \mathbf{C}) = \operatorname{add}_{2}(\mathbf{A}, \operatorname{add}_{2}(\mathbf{B}, \mathbf{C})).$$
In a very similar manner, you can define the operation $\operatorname{add}_{3}$, and more generally $\operatorname{add}_{k}$ for adding two hypermatrices of the same size. These operations are also associative and commutative.&lt;/p&gt;
&lt;h2&gt;Cayley Transposition&lt;/h2&gt;
&lt;p&gt;A rectangular matrix $\mathbf{A}$ with size $(m, n)$ has a total of $mn$ elements. These can be rearranged into a rectangular matrix $T(\mathbf{A})$ with size $(n, m)$ by swapping the row-axis with the column-axis. This operation is called the Cayley transposition:
$$T: \mathbb{A}_{m \times n} \longrightarrow \mathbb{A}_{n \times m}.$$
The Cayley transposition is an involution:
$$T \circ T = I,$$
where $I$ is the identity operation. The operations $I$ and $T$ form $S_{2}$, the symmetric group of degree 2.&lt;/p&gt;
&lt;p&gt;Similarly, an orthotopic 3-hypermatrix with size $(a, b, c)$ has a total of $abc$ elements. These can be rearranged into five other orthotopic 3-hypermatrices, corresponding to the $3! - 1 = 5$ permutations of its three axes. Thus, there are five Cayley transpositions:
$$T_{1}: \mathbb{A}_{a \times b \times c} \longrightarrow \mathbb{A}_{b \times a \times c},$$
$$T_{2}: \mathbb{A}_{a \times b \times c} \longrightarrow \mathbb{A}_{a \times c \times b},$$
$$T_{3}: \mathbb{A}_{a \times b \times c} \longrightarrow \mathbb{A}_{c \times b \times a},$$
$$T_{4}: \mathbb{A}_{a \times b \times c} \longrightarrow \mathbb{A}_{c \times a \times b},$$
$$T_{5}: \mathbb{A}_{a \times b \times c} \longrightarrow \mathbb{A}_{b \times c \times a}.$$
Three of these are involutions:
$$T_{1} \circ T_{1} = I, \quad T_{2} \circ T_{2} = I, \quad T_{3} \circ T_{3} = I.$$
The other two are each other's inverses:
$$T_{4} \circ T_{5} = I, \quad T_{5} \circ T_{4} = I.$$
The five Cayley transpositions and the identity operation form $S_{3}$, the symmetric group of degree 3.&lt;/p&gt;
&lt;p&gt;More generally, an orthotopic $k$-hypermatrix can be rearranged into $k! - 1$ different orthotopic $k$-hypermatrices. Thus, you will have $k! - 1$ Cayley transpositions $T_{j}$. Only $k$ of these are involutions. Together with the identity element, the $k! - 1$ Cayley transpositions form $S_{k}$, the symmetric group of degree $k$.&lt;/p&gt;
&lt;h2&gt;Complex Conjugation&lt;/h2&gt;
&lt;p&gt;If a rectangular matrix $\mathbf{A}$ has complex elements, then the complex conjugation operation $C$ returns a matrix $C(\mathbf{A})$ with the same size as $\mathbf{A}$, but with element-wise complex conjugation. This operation is an involution:
$$C \circ C = I$$
The operation $C$ together with the identity operation form $S_{2}$, the symmetric group of degree 2.&lt;/p&gt;
&lt;p&gt;Complex conjugation can be defined in the same way for 3-hypermatrices, and also for $k$-hypermatrices.&lt;/p&gt;
&lt;h2&gt;Hermite Transposition&lt;/h2&gt;
&lt;p&gt;The Hermite transposition operation $H$ on a rectangular matrix $\mathbf{A}$ is defined by composing complex conjugation with Cayley transposition:
$$H(\mathbf{A}) = C \circ T(\mathbf{A}) = T \circ C(\mathbf{A}).$$
Hermite transposition on a matrix is an involution. The operations $C$, $T$, $H$, and the identity form the group $S_{2} \times S_{2}$, which is equivalent to the dihedral group of order 4.&lt;/p&gt;
&lt;p&gt;There are five Cayley transpositions on a 3-hypermatrix, so there are five Hermite transpositions:
$$H_{j} = C \circ T_{j} = T_{j} \circ C.$$
Only three of these are involutions. The composition of two distinct Hermite transpositions is a Cayley transposition. The five Hermite transpositions, together with the five Cayley transpositions, $C$ and the identity operation form the group $S_{3} \times S_{2}$, which is equivalent to the dihedral group of order 12.&lt;/p&gt;
&lt;p&gt;A similar story holds for $k$-hypermatrices: you have $k! - 1$ Hermite transpositions, some of them are involutions, and together with the $k! - 1$ Cayley transpositions, the complex conjugation operation, and the identity operation they form the group $S_{k} \times S_{2}$ with $2 (k !)$ elements.&lt;/p&gt;
&lt;h2&gt;Multiplication&lt;/h2&gt;
&lt;p&gt;The matrix multiplication operation $\operatorname{mul}_{2}$ takes a matrix $\mathbf{A}$ with size $(m, p)$, and a matrix $\mathbf{B}$ with size $(p, n)$, and returns a matrix $\operatorname{mul}_{2}{(\mathbf{A}, \mathbf{B})}$ with size $(m, n)$. That is,
$$\operatorname{mul}_{2}: \mathbb{A}_{m \times p} \times \mathbb{A}_{p \times n} \longrightarrow \mathbb{A}_{m \times n}.$$
If the elements of $\mathbf{A}$ are denoted by $A_{\alpha \mu}$, the elements of $\mathbf{B}$ are denoted by $B_{\mu \beta}$, and the elements of $\mathbf{C} = \operatorname{mul}_{2}{(\mathbf{A}, \mathbf{B})}$ are denoted by $C_{\alpha \beta}$, then
$$C_{\alpha \beta} = \sum_{\mu = 1}^{p} A_{\alpha \mu} B_{\mu \beta}.$$
That is, the elements of $\mathbf{C}$ are found by contracting the column-axis of $\mathbf{A}$ with the row-axis of $\mathbf{B}$. It is for this reason that the capacity of the column-axis of $\mathbf{A}$ must equal the capacity of the row-axis of $\mathbf{B}$.&lt;/p&gt;
&lt;p&gt;The multiplication operation satisfies the property
$$T(\operatorname{mul}_{2}{(\mathbf{A}, \mathbf{B})}) = \operatorname{mul}_{2}{(T(\mathbf{B}), T(\mathbf{A}))}.$$
This is how you distribute the Cayley transposition operation on a product of matrices.&lt;/p&gt;
&lt;p&gt;One way to motivate the matrix multiplication operation is by viewing each rectangular matrix as a line with two endpoints: the row-axis and the column-axis. The operation $\operatorname{mul}_{2}$ takes two lines and concatenates them to return another line. The concatenation contracts the column-axis of the first matrix with the row-axis of the second matrix.&lt;/p&gt;
&lt;p&gt;I want the 3-hypermatrix multiplication operation $\operatorname{mul}_{3}$ to return a 3-hypermatrix. A 3-hypermatrix has three axes. Viewing each orthotopic 3-hypermatrix as a triangle (a 2-simplex), it appears one needs to concatenate three triangles to return another triangle. This leads me to introduce the triangle product operation, which is a ternary operation:
$$\operatorname{mul}_{3}: \mathbb{A}_{a \times p \times q} \times \mathbb{A}_{p \times b \times r} \times \mathbb{A}_{q \times r \times c} \longrightarrow \mathbb{A}_{a \times b \times c}.$$
Let $\mathbf{A}$ be a 3-hypermatrix with size $(a, p, q)$, $\mathbf{B}$ be a 3-hypermatrix with size $(p, b, r)$, and $\mathbf{C}$ be a 3-hypermatrix with size $(q, r, c)$. The triangle product $\mathbf{D} = \operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}$ is a 3-hypermatrix with size $(a, b, c)$. The elements of $\mathbf{D}$ are given by
$$D_{\alpha \beta \gamma} = \sum_{\mu = 1}^{p} \sum_{\nu = 1}^{q} \sum_{\rho = 1}^{r} A_{\alpha \mu \nu} B_{\mu \beta \rho} C_{\nu \rho \gamma}.$$
Here are more details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The 1-axis of $\mathbf{A}$ survives as the 1-axis of $\mathbf{D}$.&lt;/li&gt;
&lt;li&gt;The 2-axis of $\mathbf{A}$ is contracted with the 1-axis of $\mathbf{B}$.&lt;/li&gt;
&lt;li&gt;The 3-axis of $\mathbf{A}$ is contracted with the 1-axis of $\mathbf{C}$.&lt;/li&gt;
&lt;li&gt;The 2-axis of $\mathbf{B}$ survives as the 2-axis of $\mathbf{D}$.&lt;/li&gt;
&lt;li&gt;The 3-axis of $\mathbf{B}$ is contracted with the 2-axis of $\mathbf{C}$.&lt;/li&gt;
&lt;li&gt;The 3-axis of $\mathbf{C}$ survives as the 3-axis of $\mathbf{D}$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The triangle product satisfies these properties:
$$T_{1}(\operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}) = \operatorname{mul}_{3}{(T_{1}(\mathbf{B}), T_{1}(\mathbf{A}), T_{1}(\mathbf{C}))},$$
$$T_{2}(\operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}) = \operatorname{mul}_{3}{(T_{2}(\mathbf{A}), T_{2}(\mathbf{C}), T_{2}(\mathbf{B}))},$$
$$T_{3}(\operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}) = \operatorname{mul}_{3}{(T_{3}(\mathbf{C}), T_{3}(\mathbf{B}), T_{3}(\mathbf{A}))},$$
$$T_{4}(\operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}) = \operatorname{mul}_{3}{(T_{4}(\mathbf{C}), T_{4}(\mathbf{A}), T_{4}(\mathbf{B}))},$$
$$T_{5}(\operatorname{mul}_{3}{(\mathbf{A}, \mathbf{B}, \mathbf{C})}) = \operatorname{mul}_{3}{(T_{5}(\mathbf{B}), T_{5}(\mathbf{C}), T_{5}(\mathbf{A}))}.$$
These are natural generalizations of the properties for matrices.&lt;/p&gt;
&lt;p&gt;Presumably, for the case of $k$-hypermatrices, the multiplication operation $\operatorname{mul}_{k}$ takes $k$ orthotopic $k$-hypermatrices and returns another orthotopic $k$-hypermatrix. The contraction is done in such a way as to preserve the $k$-simplex structure.&lt;/p&gt;
&lt;p&gt;I will explore more properties of the triangle product in a future post.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: '#3e3f3a ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="hypermatrix"></category></entry><entry><title>Tesseracts and Pentatopes</title><link href="http://meirizarrygelpi.github.io/posts/2015/Apr/tesseracts-and-pentatopes/" rel="alternate"></link><updated>2015-04-17T00:00:00-04:00</updated><author><name>M.E. Irizarry-Gelpí</name></author><id>tag:meirizarrygelpi.github.io,2015-04-17:posts/2015/Apr/tesseracts-and-pentatopes/</id><summary type="html">&lt;p&gt;Recall the factorial function $n!$
$$n! = \prod_{k = 1}^{n}k$$
and the binomial coefficients $B(n, k)$:
$$B(n, k) \equiv \frac{n!}{(n - k)! k!}$$
With the binomial coefficients, you can define the $n$-th $k$-simplex number $S_{k}(n)$:
$$S_{k}(n) \equiv B(n - k + 1, k)$$
When $k = 1$, you have the &lt;strong&gt;line&lt;/strong&gt; numbers:
$$S_{1}(n) = n$$
When $k = 2$, you have the &lt;strong&gt;triangle&lt;/strong&gt; numbers:
$$S_{2}(n) = \frac{n (n + 1)}{2}$$
When $k = 3$, you have the &lt;strong&gt;tetrahedron&lt;/strong&gt; numbers:
$$S_{3}(n) = \frac{n (n + 1)(n + 2)}{6}$$
When $k = 4$, you have the &lt;strong&gt;pentatope&lt;/strong&gt; numbers:
$$S_{4}(n) = \frac{n (n + 1)(n + 2)(n + 3)}{24}$$
Besides the $k$-simplex numbers, you also have the $n$-th $k$-cube number $C_{k}(n)$:
$$C_{k}(n) = n^{k}$$
The cases $k = 2$, $k = 3$, and $k = 4$ are, respectively, the &lt;strong&gt;square&lt;/strong&gt;, &lt;strong&gt;cube&lt;/strong&gt;, and &lt;strong&gt;tesseract&lt;/strong&gt; numbers. The $n$-th $k$-cube number corresponds to the number of entries in a $k$-array of size $n$. For example, a 2-array of size $n$ is an $n \times n$ square matrix. I have been thinking about $k$-simplex and $k$-cube numbers lately because I have been thinking about square matrices and cubic hypermatrices.&lt;/p&gt;
&lt;p&gt;The $k$-volume of a $k$-cube and the $k$-volume of a $k$-simplex are related via:
$$\text{vol}(C_{k}) = k! \times \text{vol}(S_{k})$$
Trivially,
$$C_{1}(n) = S_{1}(n)$$
That is, a 1-cube is also a 1-simplex. As a first nontrivial example, take $k = 2$. A square can be divided into two triangles with the same area. You can translate this statement into a property of square matrices. An $n \times n$ square matrix has $n^{2}$ entries (its "area"). These $n^{2}$ entries can be divided into two identical triangular domains with $S_{2}(n - 1)$ entries, and one linear domain between the two triangles with $S_{1}(n)$ entries. Thus,
$$C_{2}(n) = S_{1}(n) + 2 S_{2}(n - 1)$$
Equivalently, you can absorb the interface between the two triangles into one of them, and arrive at the result that the sum of two consecutive triangle numbers is a square number:
$$C_{2}(n) = S_{2}(n) + S_{2}(n - 1)$$
But here the size of each triangular domain is different.&lt;/p&gt;
&lt;p&gt;Similarly, a cube can be divided into six tetrahedra with the same volume. You can translate this statement into a property of $n \times n \times n$ hypermatrices. An $n \times n \times n$ hypermatrix has $n^{3}$ entries (its "volume"). These entries can be divided into six identical tetrahedral domains with $S_{3}(n-2)$ entries, six identical triangular domains with $S_{2}(n-1)$ entries, and one linear domain with $S_{1}(n)$ entries. Thus,
$$C_{3}(n) = S_{1}(n) + 6 S_{2}(n - 1) + 6 S_{3}(n - 2)$$
Since
$$S_{3}(n+1) = S_{2}(n+1) + S_{3}(n)$$
you can absorb the interface triangular domains into the tetrahedral domains.&lt;/p&gt;
&lt;p&gt;I tried to find the analogous result in four dimensions. Since $4! = 24$, a tesseract can be divided into 24 identical pentatopes. Thus, you can imagine that
$$C_{4}(n) = \ldots + 24 S_{4}(n - 3)$$
It took me some effort to find the full result:
$$C_{4}(n) = S_{1}(n) + 14 S_{2}(n - 1) + 36 S_{3}(n - 2) + 24 S_{4}(n - 3)$$
That is, you can divide a tesseract array into one linear array, 14 triangular arrays, 36 tetrahedral arrays, and 24 pentatopic arrays. I found this by first writing
$$C_{4}(n) = a S_{1}(n) + b S_{2}(n - 1) + c S_{3}(n - 2) + 24 S_{4}(n - 3)$$
and then solving the equation $C_{4}(n) - n^{4} = 0$. Using this technique you can also show that
$$C_{5}(n) = S_{1}(n) + 30 S_{2}(n - 1) + 150 S_{3}(n - 2) + 240 S_{4}(n - 3) + 120 S_{5}(n - 4)$$
That is, you can divide a 5-cube into a one 1-simplex array, 30 2-simplex arrays, 150 3-simplex arrays, 240 4-simplex arrays, and 120 5-simplex arrays.&lt;/p&gt;
&lt;p&gt;It seems that in general, you have
$$C_{k}(n) = \sum_{l = 1}^{k} N_{k}(l) S_{l}(n - l + 1)$$
For a long time I wondered if there is a neat expression for $N_{k}(l)$. I have to confessed of being lazy and not actively trying to find $N_{k}(l)$ based on what I know of $C_{k}(n)$ and $S_{k}(n)$. In the end, I rediscovered the &lt;a href="https://oeis.org/"&gt;Online Encyclopedia of Integer Sequences&lt;/a&gt; and searched "24, 36, 14, 1" there. The first hit is the sequence &lt;a href="https://oeis.org/A090582"&gt;A090582&lt;/a&gt;. After searching for "1, 14, 36, 24" I found the sequence &lt;a href="https://oeis.org/A019538"&gt;A019538&lt;/a&gt;. Both of these sequences are related to Stirling numbers of the second kind.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: '#3e3f3a ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="geometry"></category></entry><entry><title>Cross-Ratio Versus Conformal Ratio</title><link href="http://meirizarrygelpi.github.io/posts/2015/Feb/cross-vs-conformal/" rel="alternate"></link><updated>2015-02-01T00:00:00-05:00</updated><author><name>M.E. Irizarry-Gelpí</name></author><id>tag:meirizarrygelpi.github.io,2015-02-01:posts/2015/Feb/cross-vs-conformal/</id><summary type="html">&lt;p&gt;I recently learned the difference between a cross-ratio invariant and a conformal ratio invariant, thanks to this &lt;a href="http://en.wikipedia.org/wiki/Cross-ratio"&gt;Wikipedia entry&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Cross-Ratio&lt;/h2&gt;
&lt;p&gt;The cross-ratio is a &lt;strong&gt;projective&lt;/strong&gt; invariant. Given the coordinates of four points on the complex plane, the &lt;strong&gt;cross-ratio&lt;/strong&gt; is defined as
$$P(1, 2, 3, 4) = \frac{(z_{1} - z_{3}) (z_{2} - z_{4})}{(z_{2} - z_{3}) (z_{1} - z_{4})} .$$
It is invariant under &lt;strong&gt;fractional linear transformations&lt;/strong&gt; of the form
$$ z \longrightarrow \frac{a z + b}{c z + d} .$$
There is always the arbitrariness of how to define the cross-ratio. After all, there are $4! = 24$ permutations of the coordinates, so you can argue that there are 24 possible cross-ratios for a given quartet of coordinates. However, note that if you swap two pairs you again obtain the same cross-ratio. That is,
$$P(1, 2, 3, 4) = P(2, 1, 4, 3) = P(3, 4, 1, 2) = P(4, 3, 2, 1) .$$
This means that the 24 permutations must split into six inequivalent classes, each with four permutations related by the above relation. Representatives of each of these six inequivalent classes are:
$$P(1, 2, 3, 4) = p \quad P(1, 2, 4, 3) = \frac{1}{p} \quad P(1, 3, 4, 2) = \frac{1}{1 - p} \quad P(1, 3, 2, 4) = 1 - p \quad P(1, 4, 3, 2) = \frac{p}{1 - p} \quad P(1, 4, 2, 3) = \frac{1 - p}{p} .$$
As you can see, once the value of $p$ is given, all possible permutations are fixed, so there is really &lt;strong&gt;one&lt;/strong&gt; independent cross-ratio for any given quartet of coordinates.&lt;/p&gt;
&lt;h2&gt;Conformal Ratio&lt;/h2&gt;
&lt;p&gt;A conformal ratio is a &lt;strong&gt;conformal&lt;/strong&gt; invariant. Given the coordinates of four points on $D$-dimensional space, a &lt;strong&gt;conformal ratio&lt;/strong&gt; is defined as
$$C(1, 2, 3, 4) = \frac{(x_{1} - x_{3})^{2} (x_{2} - x_{4})^{2}}{(x_{2} - x_{3})^{2} (x_{1} - x_{4})^{2}} ,$$
where $(x_{1} - x_{3})^{2}$ means the square of the magnitude of the $D$-dimensional vector $x_{1} - x_{3}$. In some sense, after a change of basis, the cross-ratio is the square root of a conformal ratio in two dimensions.&lt;/p&gt;
&lt;p&gt;Again you encounter the arbitrariness of which of the $4! = 24$ permutations to use for the definition of a conformal ratio. Just like the cross-ratio, you find that a conformal ratio is invariant under the exchange of two pairs of coordinates. So again you find six inequivalent classes. However, unlike the cross-ratio, you find that fixing the value of the conformal ratio for one class does not fix the other five classes:
$$C(1, 2, 3, 4) = u \quad C(1, 2, 4, 3) = \frac{1}{u} \quad C(1, 3, 4, 2) = \frac{1}{v} \quad C(1, 3, 2, 4) = v \quad C(1, 4, 3, 2) = \frac{u}{v} \quad C(1, 4, 2, 3) = \frac{v}{u} .$$
Indeed, now you have &lt;strong&gt;two&lt;/strong&gt; independent conformal ratios for a given quartet of coordinates.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: '#3e3f3a ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="conformal symmetry"></category></entry><entry><title>Points in Space</title><link href="http://meirizarrygelpi.github.io/posts/2014/May/points-in-space/" rel="alternate"></link><updated>2014-05-02T00:00:00-04:00</updated><author><name>M.E. Irizarry-Gelpí</name></author><id>tag:meirizarrygelpi.github.io,2014-05-02:posts/2014/May/points-in-space/</id><summary type="html">&lt;p&gt;Consider $N$ distinct points $P_{1}$, $P_{2}$, ..., $P_{N}$ with coordinates $x_{1}$, $x_{2}$, ..., $x_{N}$. One can draw $N^{2}$ lines connecting these $N$ points. If we ommit lines that connect a point to itself, then we have $N(N-1)/2$ possible distinct lines. Out of these, $N$ can be regarded as external lines (corresponding to the edges of a convex polygonal perimeter connecting the $N$ points) and $N(N - 3)/2$ can be regarded as internal lines (the lines inside the perimeter).&lt;/p&gt;
&lt;p&gt;We start with $N$ distinct position variables. One can imagine making a change of variables$$(x_{1}, x_{2}, ..., x_{N}) \longrightarrow (X, x_{ij})$$where $X$ describes the center-of-mass position of the system, and the $x_{ij}$ variables represent a set of $N - 1$ independent coordinate differences $x_{ij} \equiv x_{i} - x_{j}$. One can construct more than $N - 1$ coordinate differences, but it is only possible to have $N - 1$ linearly independent ones. Indeed, one can write$$N - 1 = \frac{N(N-1)}{2} + N - 1 - \frac{N(N-1)}{2}$$which can be rewritten as$$N - 1 = \frac{N(N-1)}{2} - \frac{(N - 2)(N - 1)}{2}$$So if we want to keep all possible $N(N-1)/2$ coordinate differences available, we need to introduce $(N-2)(N-1)/2$ auxilliary variables (i.e. Lagrange multipliers) that enforce the linear constraints that leave only $N-1$ linearly-independent ones.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: '#3e3f3a ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="combinatorics"></category><category term="graph theory"></category></entry></feed>